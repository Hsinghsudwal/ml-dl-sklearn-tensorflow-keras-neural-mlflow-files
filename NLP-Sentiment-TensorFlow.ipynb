{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e825f6a-575e-4165-a426-4f9d4711e94d",
   "metadata": {},
   "source": [
    "## Build an NLP Model for Sentiment Analysis Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f55674f-e61c-46c6-8f1a-1d5219f8a516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\I'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\I'\n",
      "C:\\Users\\sudwa\\AppData\\Local\\Temp\\ipykernel_6576\\3726957245.py:5: SyntaxWarning: invalid escape sequence '\\I'\n",
      "  df = pd.read_csv('IMDB\\IMDB Dataset.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12517</th>\n",
       "      <td>This film was the worst film I have ever viewe...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>This Metro film is episodic, but nearly a cons...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17034</th>\n",
       "      <td>\"Going Berserk\" is actually one of the funnies...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29286</th>\n",
       "      <td>I always wondered what happened with that magi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46344</th>\n",
       "      <td>Joe Don Baker is...Thomas Jefferson Geronimo, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "12517  This film was the worst film I have ever viewe...  negative\n",
       "4236   This Metro film is episodic, but nearly a cons...  positive\n",
       "17034  \"Going Berserk\" is actually one of the funnies...  positive\n",
       "29286  I always wondered what happened with that magi...  positive\n",
       "46344  Joe Don Baker is...Thomas Jefferson Geronimo, ...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. load dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('IMDB\\IMDB Dataset.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68573d28-4942-4995-8a25-852c3e92be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sudwa\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 9.2/390.3 MB 47.4 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 19.9/390.3 MB 48.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 29.9/390.3 MB 45.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 34.3/390.3 MB 38.9 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 47.7/390.3 MB 43.4 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 65.3/390.3 MB 48.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 71.0/390.3 MB 44.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 74.7/390.3 MB 41.4 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 79.2/390.3 MB 39.5 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 89.4/390.3 MB 40.2 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 100.7/390.3 MB 41.5 MB/s eta 0:00:07\n",
      "   ---------- ---------------------------- 104.3/390.3 MB 39.4 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 107.5/390.3 MB 37.7 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 109.6/390.3 MB 35.7 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 121.4/390.3 MB 36.9 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 121.4/390.3 MB 36.9 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 125.8/390.3 MB 33.9 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 126.1/390.3 MB 31.8 MB/s eta 0:00:09\n",
      "   ------------ -------------------------- 127.9/390.3 MB 30.8 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 130.5/390.3 MB 29.8 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 135.8/390.3 MB 29.5 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 138.7/390.3 MB 29.0 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 139.5/390.3 MB 27.7 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 141.8/390.3 MB 27.0 MB/s eta 0:00:10\n",
      "   -------------- ------------------------ 147.1/390.3 MB 26.9 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 152.3/390.3 MB 26.8 MB/s eta 0:00:09\n",
      "   --------------- ----------------------- 154.4/390.3 MB 26.1 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 157.3/390.3 MB 25.7 MB/s eta 0:00:10\n",
      "   --------------- ----------------------- 159.9/390.3 MB 25.2 MB/s eta 0:00:10\n",
      "   ---------------- ---------------------- 166.5/390.3 MB 25.4 MB/s eta 0:00:09\n",
      "   ---------------- ---------------------- 169.9/390.3 MB 25.1 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 173.0/390.3 MB 24.8 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 175.9/390.3 MB 24.4 MB/s eta 0:00:09\n",
      "   ----------------- --------------------- 176.7/390.3 MB 24.3 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 192.7/390.3 MB 25.2 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 199.5/390.3 MB 25.5 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 202.4/390.3 MB 25.1 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 205.8/390.3 MB 24.9 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 208.7/390.3 MB 24.6 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 215.2/390.3 MB 24.7 MB/s eta 0:00:08\n",
      "   ---------------------- ---------------- 221.8/390.3 MB 25.0 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 230.9/390.3 MB 25.2 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 235.7/390.3 MB 25.2 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 239.1/390.3 MB 25.0 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 242.2/390.3 MB 24.7 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 243.8/390.3 MB 24.4 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 256.6/390.3 MB 25.1 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 272.1/390.3 MB 25.7 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 286.8/390.3 MB 26.0 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 293.6/390.3 MB 25.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 305.7/390.3 MB 25.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 318.2/390.3 MB 26.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 318.2/390.3 MB 26.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 326.9/390.3 MB 25.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 326.9/390.3 MB 25.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 326.9/390.3 MB 25.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 329.8/390.3 MB 24.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 329.8/390.3 MB 24.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 329.8/390.3 MB 24.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 352.3/390.3 MB 24.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 367.8/390.3 MB 25.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.7/390.3 MB 25.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 28.1 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.68.0-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 26.5 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 12.1/26.4 MB 58.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.4 MB 56.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 57.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 57.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 57.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 25.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 33.6 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.0 keras-3.6.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc3dcc8c-a833-4684-ae81-cf4139197a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Data Cleaning, Tokenization and Preprocessing\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabet characters\n",
    "    return text.lower().strip()\n",
    "\n",
    "# Clean the reviews\n",
    "df['review'] = df['review'].apply(clean_text)\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['review'])\n",
    "sequences = tokenizer.texts_to_sequences(df['review'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93469843-dca7-416d-ba6f-b64f4ddf43ef",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "We cleaned the text by removing HTML tags and special characters.\n",
    "We tokenized the text, converting it into numerical sequences.\n",
    "We padded the sequences to ensure they all have the same length (200 words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0fd253e-69ee-4603-972c-35b9cb83d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. # Convert sentiment labels to binary\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# Splitting the data into features (X) and labels (y)\n",
    "X = padded_sequences\n",
    "y = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eddf1d5-449e-401e-983e-f0c4ce6b19aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Splitting the Data into Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5daedc5c-2f50-463e-b879-d9c8866dc69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0703b-8861-4e18-90c1-bfd10f8dfbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudwa\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 289ms/step - accuracy: 0.6992 - loss: 0.5602 - val_accuracy: 0.8165 - val_loss: 0.4178\n",
      "Epoch 2/10\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 234ms/step - accuracy: 0.8687 - loss: 0.3236 - val_accuracy: 0.8544 - val_loss: 0.3414\n",
      "Epoch 3/10\n",
      "\u001b[1m 123/1000\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:15\u001b[0m 223ms/step - accuracy: 0.9106 - loss: 0.2338"
     ]
    }
   ],
   "source": [
    "#5. Building the Neural Network with TensorFlow\n",
    "#create a simple neural network with an Embedding layer, followed by two LSTM layers, and a Dense output layer.\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16, input_length=200),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670c0c66-14d4-4e6a-9c56-5efedd459464",
   "metadata": {},
   "source": [
    "Model Explanation\n",
    "Embedding Layer: Converts word indices into dense vectors of fixed size (16 dimensions).\n",
    "LSTM Layers: These layers capture patterns in the text over sequences of words.\n",
    "Dense Layer: Reduces the dimensionality of the features.\n",
    "Output Layer: Uses the sigmoid activation function to predict the probability of being positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945f5b6-939f-4344-a300-f6692c2c1e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Visualizing Model Performance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d86d8-9bb2-4ad0-9e33-f02a5422eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Evaluating the Model\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08bdaea-53e9-49ea-9119-8cfc2653db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Making Predictions\n",
    "\n",
    "sample_reviews = [\n",
    "    \"I absolutely loved this movie! The plot was thrilling and the characters were so well developed.\",\n",
    "    \"The film was a disaster. Poor acting and a predictable storyline.\"\n",
    "]\n",
    "\n",
    "sample_sequences = tokenizer.texts_to_sequences(sample_reviews)\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=200)\n",
    "\n",
    "predictions = model.predict(sample_padded)\n",
    "print([\"Positive\" if prob > 0.5 else \"Negative\" for prob in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae774df2-623f-4c9a-902e-0062eaa08bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
